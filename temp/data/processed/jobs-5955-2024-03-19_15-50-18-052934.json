{"date": "2024-03-03T08:00:00.000Z", "title": "Senior Software Engineer, Machine Learning", "company": "Red Hat Software", "job_apply_link": "https://us-redhat.icims.com/jobs/101477/us-remote/job", "company_url": "http://www.redhat.com", "company_type": "Information", "job_type": "FULLTIME", "job_is_remote": "Not Remote", "job_offer_expiration_date": "2024-05-26T07:00:00.000Z", "salary_low": null, "salary_high": null, "salary_currency": null, "salary_period": null, "job_benefits": null, "city": "Remote", "state": "OR", "country": "US", "apply_options": "https://us-redhat.icims.com/jobs/101477/us-remote/job\nhttps://us.bebee.com/job/20240310-52958e9268c948eb63bc0173509974fb", "required_skills": "Fulltime-Regular: Employee", "required_experience": "no_experience_required: False, \nrequired_experience_in_months: None, \nexperience_mentioned: True, \nexperience_preferred: False", "required_education": "postgraduate_degree: False, \nprofessional_certification: False, \nhigh_school: False, \nassociates_degree: False, \nbachelors_degree: False, \ndegree_mentioned: True, \ndegree_preferred: True, \nprofessional_certification_mentioned: False", "description": "About the job\n\nDo you want to be part of a team that is focused on scaling the deployment, prompt-tuning, and monitoring of Foundation Models and Large Language Models (LLMs)? The OpenShift AI team is looking for a Senior Software Engineer with Kubernetes and Machine Learning experience to join our rapidly growing engineering team. Our team\u2019s focus is to make machine learning model deployment and monitoring seamless and scalable across the hybrid cloud and the edge. This is a very exciting opportunity to build and impact the next generation of hybrid cloud MLOps platforms.\n\nIn this role, you'll be contributing as a technical expert for the model serving and inference runtimes features of the open source Open Data Hub project and OpenShift AI by actively participating in KServe, Kubeflow, HuggingFace, vLLM, and several other open source communities. You will work as part of an evolving development team to rapidly design, secure, build, test and release model serving, trustworthy AI, and model registry capabilities. The role is primarily an individual contributor who will be a key notable contributor to the MLOps upstream communities and collaborate closely with the internal cross-functional development teams.\n\nWhat you will do\n\u2022 Be an influencer and leader in MLOps related open source communities to help build an active MLOps open source ecosystem for Open Data Hub and OpenShift AI\n\u2022 Act as a Model Serving SME within Red Hat by supporting customer facing discussions, presenting at technical conferences, and evangelizing OpenShift AI within the internal community of practices\n\u2022 Architect and design new features in collaboration with open source communities such as KubeFlow and KServe\n\u2022 Contribute to developing and integrating model inference and runtimes in OpenShift AI product\n\u2022 Collaborate with our product management and customer engineering teams to identify and expand product functionalities\n\u2022 Mentor, influence, and coach a team of distributed engineers\n\nWhat you will bring\n\u2022 Hands on experience in deploying and maintaining machine learning models in production environments\n\u2022 Ideally work Hybrid in Raleigh or be remote Eastern Time Zone\n\u2022 Solid understanding of the fundamentals of model inferencing and runtimes architectures\n\u2022 Advanced level knowledge and experience with development in Go, and Python\n\u2022 Advanced level of experience with Kubernetes\n\u2022 Excellent written and verbal communication skills; fluent English language skills\n\nThe following will be considered a plus:\n\u2022 Bachelor's degree in statistics, mathematics, computer science, operations research, or a related quantitative field, or equivalent expertise; Master\u2019s or PhD is a big plus\n\u2022 Experience in engineering, consulting or another field related to model serving and monitoring, model registry, deep neural networks, in a customer environment or supporting a data science team\n\u2022 Familiarity with popular python machine learning libraries such as PyTorch, Tensorflow, and Hugging Face\n\u2022 Experience with monitoring and alerting tools such as Prometheus\n\nThe salary range for this position is $111,260 - $183,530. Actual offer will be based on your qualifications.\n\n#LI-REMOTE\n\n#LI-LS2\n\n#LI-REMOTE #LI-HM1", "highlights": "\nQualifications:\n Hands on experience in deploying and maintaining machine learning models in production environments, Ideally work Hybrid in Raleigh or be remote Eastern Time Zone, Solid understanding of the fundamentals of model inferencing and runtimes architectures, Advanced level knowledge and experience with development in Go, and Python, Advanced level of experience with Kubernetes, Excellent written and verbal communication skills; fluent English language skills, Bachelor's degree in statistics, mathematics, computer science, operations research, or a related quantitative field, or equivalent expertise; Master\u2019s or PhD is a big plus, Experience in engineering, consulting or another field related to model serving and monitoring, model registry, deep neural networks, in a customer environment or supporting a data science team, Familiarity with popular python machine learning libraries such as PyTorch, Tensorflow, and Hugging Face, Experience with monitoring and alerting tools such as Prometheus, \nResponsibilities:\n In this role, you'll be contributing as a technical expert for the model serving and inference runtimes features of the open source Open Data Hub project and OpenShift AI by actively participating in KServe, Kubeflow, HuggingFace, vLLM, and several other open source communities, You will work as part of an evolving development team to rapidly design, secure, build, test and release model serving, trustworthy AI, and model registry capabilities, Be an influencer and leader in MLOps related open source communities to help build an active MLOps open source ecosystem for Open Data Hub and OpenShift AI, Act as a Model Serving SME within Red Hat by supporting customer facing discussions, presenting at technical conferences, and evangelizing OpenShift AI within the internal community of practices, Architect and design new features in collaboration with open source communities such as KubeFlow and KServe, Contribute to developing and integrating model inference and runtimes in OpenShift AI product, Collaborate with our product management and customer engineering teams to identify and expand product functionalities, Mentor, influence, and coach a team of distributed engineers, \nBenefits:\n The salary range for this position is $111,260 - $183,530", "resume_similarity": null}