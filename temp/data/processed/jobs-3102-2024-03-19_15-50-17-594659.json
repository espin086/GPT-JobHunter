{"date": "2024-03-14T16:40:19.000Z", "title": "Data Engineer", "company": "Cogliano IT Staffing", "job_apply_link": "https://www.ziprecruiter.com/c/Cogliano-IT-Staffing/Job/Data-Engineer/-in-Phoenix,AZ?jid=1001383cc98fd733", "company_url": null, "company_type": null, "job_type": "FULLTIME", "job_is_remote": "Remote", "job_offer_expiration_date": "2024-04-15T00:00:00.000Z", "salary_low": null, "salary_high": null, "salary_currency": null, "salary_period": null, "job_benefits": null, "city": "Phoenix", "state": "AZ", "country": "US", "apply_options": "https://www.ziprecruiter.com/c/Cogliano-IT-Staffing/Job/Data-Engineer/-in-Phoenix,AZ?jid=1001383cc98fd733\nhttps://www.glassdoor.com/job-listing/data-engineer-intone-networks-JV_KO0,13_KE14,29.htm?jl=1009104742257\nhttps://ai-jobs.net/job/134739-data-engineer-i/\nhttps://www.linkedin.com/jobs/view/data-engineer-ii-at-core-group-resources-3854365137\nhttps://www.indeed.com/viewjob?jk=d7d14047fe1370f0\nhttps://jooble.org/jdp/5290390378052672206", "required_skills": null, "required_experience": "no_experience_required: False, \nrequired_experience_in_months: 60, \nexperience_mentioned: True, \nexperience_preferred: False", "required_education": "postgraduate_degree: False, \nprofessional_certification: False, \nhigh_school: False, \nassociates_degree: False, \nbachelors_degree: False, \ndegree_mentioned: True, \ndegree_preferred: True, \nprofessional_certification_mentioned: False", "description": "Data Engineer needed for a Direct Hire position in Phoenix, AZ! Position will be remote, but candidate needs to live within a reasonable distance of Phoenix.\n\nYou will be project leader and independent contributor on a fast-growing Data Engineering team pursuing a vision of analytics-driven company. Your expertise in data engineering and software engineering will enable and empower our organization to build and deploy data driven solutions to production. We understand that our data does not reach its full potential until it is analyzed, and insights effectively communicated to the enterprise. You will work in close collaboration with operations, subject matter experts, data scientists, and software engineers to develop advanced, highly automated data products. You will be a champion of DataOps, and agile practices; actively participating in project teams to drive value.\n\u2022 Agile Project Work: Work as a project leader in cross-functional, geographically distributed agile teams of highly skilled data engineers, software/machine learning engineers, data scientists, DevOps engineers, designers, product managers, technical delivery teams, and others to continuously innovate analytic solutions.\n\u2022 Design, develop, and review real-time/bulk data pipelines from a variety of sources (streaming data, APIs, data warehouse, messages, images, video, etc) while also coach jr. team members.\n\u2022 Ensure the project team is following established design patterns for data ingest, transformation, and egress.\n\u2022 Develop documentation of Data Lineage and Data Dictionaries to create a broad awareness of the enterprise data model and its applications.\n\u2022 Apply best practices within DataOps (Version Control, P.R. Based Development, Schema Change Control, CI/CD, Deployment Automation, Test Automation, Shift left on Security, Loosely Coupled Architectures, Monitoring, Proactive Notifications)\n\u2022 Problem Solving/Project Leadership: Provide thought leadership in problem solving to enrich possible solutions by constructively challenging paradigms and actively soliciting other opinions. Actively participate in R&D initiatives\n\u2022 Architecture: Utilize modern cloud technologies and employ best practices from DevOps/DataOps to produce enterprise quality production Python and SQL code with minimal errors. Identify and direct the implementation code optimization opportunities during code review sessions and proactively pull in external experts as needed.\n\u2022 Self-Development: Flexibly seek out new work or training opportunities to broaden experience. Independently research the latest technologies and openly discuss applications within the department.\n\u2022 Perform other duties as requested.\nPreferred Qualifications:\n\u2022 Working knowledge of Azure Stream Architectures, DBT, Schema Change tools, Data Dictionary tools, Azure Machine Learning Environment, GIS Data\n\u2022 Working knowledge of Software Engineering and Object Orient Programming Principles\n\u2022 Working knowledge of Distributed Parallel Processing Environments such as Spark or Snowflake\n\u2022 Working knowledge of problem solving/root cause analysis on Production workloads\n\u2022 Working knowledge of Agile, Scrum, and Kanban\n\u2022 Working knowledge of workflow orchestration using tools such as Airflow, Prefect, Dagster, or similar tooling\n\u2022 Working knowledge with CI/CD and automation tools like Jenkins or Azure DevOps\n\u2022 Experience with containerization tools such as Docker.\n\u2022 Strong verbal and written communication skills in English language\n\nMinimum Requirements:\n\u2022 Bachelor's degree in engineering, computer science, analytical field (Statistics, Mathematics, etc.) or related discipline and five (5) years of relevant work experience\nOR\n\u2022 Master's in engineering, computer science, analytical field (Statistics, Mathematics, etc.) or related discipline and three (3) year of relevant work experience\nOR\n\u2022 Ph.D. in engineering, computer science, analytical field (Statistics, Mathematics, etc.) or related discipline and one (1) year of relevant work experience\n\u2022 Strong experience in at least three areas:\n\u2022 Knowledgeable Practitioner of SQL development with experience designing high quality, production SQL codebases\n\u2022 Knowledgeable Practitioner of Python development with experience designing high quality, production Python codebases\n\u2022 Knowledgeable Practitioner in data engineering, software engineering, and Client systems architecture\n\u2022 Knowledgeable Practitioner of data modeling\n\u2022 Experience applying software development best practices in data engineering projects, including Version Control, P.R. Based Development, Schema Change Control, CI/CD, Deployment Automation, Test Driven Development/Test Automation, Shift left on Security, Loosely Coupled Architectures, Monitoring, Proactive Notifications using Python and SQL\n\u2022 Data science experience wrangling data, model selection, model training, modeling validation, e.g., Operational Readiness Evaluator and Model Development and Assessment Framework, and deployment at scale", "highlights": "\nQualifications:\n Position will be remote, but candidate needs to live within a reasonable distance of Phoenix, Bachelor's degree in engineering, computer science, analytical field (Statistics, Mathematics, etc.) or related discipline and five (5) years of relevant work experience, Strong experience in at least three areas:, Knowledgeable Practitioner of SQL development with experience designing high quality, production SQL codebases, Knowledgeable Practitioner in data engineering, software engineering, and Client systems architecture, Knowledgeable Practitioner of data modeling, Experience applying software development best practices in data engineering projects, including Version Control, P.R. Based Development, Schema Change Control, CI/CD, Deployment Automation, Test Driven Development/Test Automation, Shift left on Security, Loosely Coupled Architectures, Monitoring, Proactive Notifications using Python and SQL, Data science experience wrangling data, model selection, model training, modeling validation, e.g., Operational Readiness Evaluator and Model Development and Assessment Framework, and deployment at scale, \nResponsibilities:\n Your expertise in data engineering and software engineering will enable and empower our organization to build and deploy data driven solutions to production, You will work in close collaboration with operations, subject matter experts, data scientists, and software engineers to develop advanced, highly automated data products, You will be a champion of DataOps, and agile practices; actively participating in project teams to drive value, Agile Project Work: Work as a project leader in cross-functional, geographically distributed agile teams of highly skilled data engineers, software/machine learning engineers, data scientists, DevOps engineers, designers, product managers, technical delivery teams, and others to continuously innovate analytic solutions, Design, develop, and review real-time/bulk data pipelines from a variety of sources (streaming data, APIs, data warehouse, messages, images, video, etc) while also coach jr, Ensure the project team is following established design patterns for data ingest, transformation, and egress, Develop documentation of Data Lineage and Data Dictionaries to create a broad awareness of the enterprise data model and its applications, Apply best practices within DataOps (Version Control, P.R. Based Development, Schema Change Control, CI/CD, Deployment Automation, Test Automation, Shift left on Security, Loosely Coupled Architectures, Monitoring, Proactive Notifications), Problem Solving/Project Leadership: Provide thought leadership in problem solving to enrich possible solutions by constructively challenging paradigms and actively soliciting other opinions, Actively participate in R&D initiatives, Architecture: Utilize modern cloud technologies and employ best practices from DevOps/DataOps to produce enterprise quality production Python and SQL code with minimal errors, Identify and direct the implementation code optimization opportunities during code review sessions and proactively pull in external experts as needed, Self-Development: Flexibly seek out new work or training opportunities to broaden experience, Perform other duties as requested", "resume_similarity": null}