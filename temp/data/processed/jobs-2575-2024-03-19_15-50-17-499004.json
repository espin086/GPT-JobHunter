{"date": "2024-02-27T00:00:00.000Z", "title": "Senior Data Engineer at Kforce Technology Cincinnati, OH", "company": "Kforce Technology", "job_apply_link": "https://quickstripnj.com/gig/job/senior-data-engineer-at-kforce-technology-cincinnati-oh-T1M4WnRRQmxFNG5UWEN0cElFYUxxTFBIRHc9PQ==", "company_url": null, "company_type": null, "job_type": "FULLTIME", "job_is_remote": "Not Remote", "job_offer_expiration_date": "2024-04-27T00:00:00.000Z", "salary_low": null, "salary_high": null, "salary_currency": null, "salary_period": null, "job_benefits": null, "city": "Cincinnati", "state": "OH", "country": "US", "apply_options": "https://quickstripnj.com/gig/job/senior-data-engineer-at-kforce-technology-cincinnati-oh-T1M4WnRRQmxFNG5UWEN0cElFYUxxTFBIRHc9PQ==\nhttps://wisconsin.tarta.ai/j/TUD6d4wBcRajQcTjsxgq1223-physical-medicine-and-rehabilitation-madison-wi-in-brown-deer-wi-at-mrg-exams", "required_skills": null, "required_experience": "no_experience_required: False, \nrequired_experience_in_months: None, \nexperience_mentioned: False, \nexperience_preferred: False", "required_education": "postgraduate_degree: False, \nprofessional_certification: False, \nhigh_school: False, \nassociates_degree: False, \nbachelors_degree: False, \ndegree_mentioned: False, \ndegree_preferred: False, \nprofessional_certification_mentioned: False", "description": "Senior Data Engineer job at Kforce Technology. Cincinnati, OH. Kforce has a client in Cincinnati, OH that is seeking a Senior Data Engineer to join their team on a 6-month contract to hire basis. The current team is small with a large project. There is a lot of data acquisition, understanding and modeling needed to help get data from source systems into the the data lake. The team is leveraging all cloud-based tools in Azure today. The overall objective is to continue to hydrate data for our business partners to leverage to help drive supply chain operations and planning.\n\nSummary:\nWe're looking for individuals who can bring their core set of knowledge as well as learn new tools to provide new data and capabilities to support our ever growing Supply Chain.\n\nResponsibilities:\n\u2022 Accountable for developing and delivering technological responses to targeted business outcomes\n\u2022 Analyze, design and develop enterprise data and information architecture deliverables, focusing on data as an asset for Supply Chain and the overall enterprise\n\u2022 Understand and follow reusable standards, design patterns, guidelines, and configurations to deliver valuable data and information across the enterprise, including direct collaboration with vendors, where needed\n\u2022 Demonstrate the company's core values of respect, honesty, integrity, diversity, inclusion and safety Create and leverage Databricks notebooks to source, shape and store data using SQL, Python, PySpark\n\u2022 Utilize enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses\n\u2022 Ensure there is clarity between ongoing projects, escalating when necessary, including direct collaboration with vendors\n\u2022 Define high-level migration plans to address the gaps between the current and future state\n\u2022 Analyze technology environments to detect critical deficiencies and recommend solutions for improvement\n\u2022 Promote the reuse of data assets, including the management of the data catalog for reference", "highlights": "\nResponsibilities:\n Accountable for developing and delivering technological responses to targeted business outcomes, Analyze, design and develop enterprise data and information architecture deliverables, focusing on data as an asset for Supply Chain and the overall enterprise, Understand and follow reusable standards, design patterns, guidelines, and configurations to deliver valuable data and information across the enterprise, including direct collaboration with vendors, where needed, Demonstrate the company's core values of respect, honesty, integrity, diversity, inclusion and safety Create and leverage Databricks notebooks to source, shape and store data using SQL, Python, PySpark, Utilize enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses, Ensure there is clarity between ongoing projects, escalating when necessary, including direct collaboration with vendors, Define high-level migration plans to address the gaps between the current and future state, Analyze technology environments to detect critical deficiencies and recommend solutions for improvement, Promote the reuse of data assets, including the management of the data catalog for reference", "resume_similarity": null}