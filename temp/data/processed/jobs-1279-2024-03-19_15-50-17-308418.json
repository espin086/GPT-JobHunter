{"date": "2024-03-18T20:59:34.000Z", "title": "Senior Data Engineer", "company": "Coforge", "job_apply_link": "https://www.linkedin.com/jobs/view/senior-data-engineer-at-coforge-3859082274", "company_url": "http://www.coforge.com", "company_type": null, "job_type": "FULLTIME", "job_is_remote": "Not Remote", "job_offer_expiration_date": "2024-04-17T20:59:33.000Z", "salary_low": null, "salary_high": null, "salary_currency": null, "salary_period": null, "job_benefits": null, "city": "Paoli", "state": "PA", "country": "US", "apply_options": "https://www.linkedin.com/jobs/view/senior-data-engineer-at-coforge-3859082274\nhttps://jobright.ai/jobs/info/65f8bb9b4384d533480241af", "required_skills": null, "required_experience": "no_experience_required: False, \nrequired_experience_in_months: None, \nexperience_mentioned: True, \nexperience_preferred: False", "required_education": "postgraduate_degree: False, \nprofessional_certification: False, \nhigh_school: False, \nassociates_degree: False, \nbachelors_degree: True, \ndegree_mentioned: False, \ndegree_preferred: False, \nprofessional_certification_mentioned: False", "description": "We at Coforge are seeking Senior ADF Data Engineer with mentioned skill-set and who can work onsite from Paoli, PA location.\n\nRole: Senior ADF Data Engineer\n\nLocation: Paoli, PA\n\nMode of Hire: Full Time\n\nExperience Required: 10+ years\n\nKey Skills: Azure Data Factory (ADF), ETL, SQL, stored procedures, Python/PySpark, Indexing.\n\nSkills Required:-\n\n\u2022 Experienced ADF Data Engineer. Set-up / configure Azure based ETL solutions.\n\n\u2022 Partner with business stakeholders to gather requirements and translate them into technical specifications and process documentation for IT counterparts (onshore and offshore).\n\n\u2022 Highly proficient in the architecture and development of an event driven data warehouse; streaming, batch, data modeling, and storage.\n\n\u2022 Advanced database knowledge; creating/optimizing SQL queries, stored procedures, functions, partitioning data, indexing, and reading execution plans.\n\n\u2022 Skilled experience in writing and troubleshooting Python/PySpark scripts to generate extracts, cleanse, conform and deliver data for consumption.\n\n\u2022 Expert level of understanding and implementing ETL architecture; data profiling, process flow, metric logging, and error handling.\n\n\u2022 Support continuous improvement by investigating and presenting alternatives to processes and technologies to an architectural review board.\n\n\u2022 Develop and ensure adherence to published system architectural decisions and development standards.\n\n\u2022 Multi-task across several ongoing projects and daily duties of varying priorities as required.\n\n\u2022 Interact with global technical teams to communicate business requirements and collaboratively build data solutions.", "highlights": "\nQualifications:\n Experience Required: 10+ years, Key Skills: Azure Data Factory (ADF), ETL, SQL, stored procedures, Python/PySpark, Indexing, Experienced ADF Data Engineer, Highly proficient in the architecture and development of an event driven data warehouse; streaming, batch, data modeling, and storage, Advanced database knowledge; creating/optimizing SQL queries, stored procedures, functions, partitioning data, indexing, and reading execution plans, Skilled experience in writing and troubleshooting Python/PySpark scripts to generate extracts, cleanse, conform and deliver data for consumption, \nResponsibilities:\n Partner with business stakeholders to gather requirements and translate them into technical specifications and process documentation for IT counterparts (onshore and offshore), Support continuous improvement by investigating and presenting alternatives to processes and technologies to an architectural review board, Develop and ensure adherence to published system architectural decisions and development standards, Multi-task across several ongoing projects and daily duties of varying priorities as required, Interact with global technical teams to communicate business requirements and collaboratively build data solutions", "resume_similarity": null}