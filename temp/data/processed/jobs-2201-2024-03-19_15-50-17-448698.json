{"date": "2024-03-18T16:27:41.000Z", "title": "Senior Data Engineer", "company": "Sun Life", "job_apply_link": "https://www.linkedin.com/jobs/view/senior-data-engineer-at-sun-life-3859018885", "company_url": "http://www.sunlife.com", "company_type": "Finance", "job_type": "FULLTIME", "job_is_remote": "Not Remote", "job_offer_expiration_date": "2024-04-17T16:27:41.000Z", "salary_low": null, "salary_high": null, "salary_currency": null, "salary_period": null, "job_benefits": null, "city": null, "state": "ND", "country": "US", "apply_options": "https://www.linkedin.com/jobs/view/senior-data-engineer-at-sun-life-3859018885", "required_skills": null, "required_experience": "no_experience_required: False, \nrequired_experience_in_months: 60, \nexperience_mentioned: True, \nexperience_preferred: False", "required_education": "postgraduate_degree: False, \nprofessional_certification: False, \nhigh_school: False, \nassociates_degree: False, \nbachelors_degree: True, \ndegree_mentioned: True, \ndegree_preferred: True, \nprofessional_certification_mentioned: True", "description": "You are as unique as your background, experience and point of view. Here, you\u2019ll be encouraged, empowered and challenged to be your best self. You'll work with dynamic colleagues - experts in their fields - who are eager to share their knowledge with you. Your leaders will inspire and help you reach your potential and soar to new heights. Every day, you'll have new and exciting opportunities to make life brighter for our Clients - who are at the heart of everything we do. Discover how you can make a difference in the lives of individuals, families and communities around the world.\n\nJob Description:\n\nGB Analytics team has a mandate to work across functions to deliver insights critical for business decisions, identify growth opportunities and use data to improve health and financial outcomes. The team collaborates closely with Canadian Data & Analytics and Enterprise Services teams.\n\nReporting to AVP, GB Analytics , you will accelerate the growth and application of analytics in Group Benefits. You will also leverage practical experience in applying varied data engineering techniques and design, develop and implement analytics use cases.\n\nWhat will you do?\n\u2022 Work with UW management and Best Practices teams to reverse engineer their existing tools, identify data needs and develop automated financial reporting capability\n\u2022 Review and translate existing macro-based (VBS) data scripts to SQL code to migrate UW tools to new cloud-based data models\n\u2022 Work directly with business stakeholders throughout the entire engagement life cycle including technical analysis, design, development, implementation and consulting efforts.\n\u2022 Provide plans and estimates for data engineering and business intelligence initiatives\n\u2022 Lead development of new batch/low-latency analytical solutions that leverages both traditional and emerging technologies\n\u2022 Design, develop and implement highly scalable data capture and transformation processes\n\u2022 Act as principal designer and reviewer for new data models, make data architectural decision, and provide coaching on data modeling and process design\n\u2022 Create effective ETLs/ELTs to move large volumes of data from various operational systems to dimensional data models for analytics consumption\n\u2022 Expand and grow data existing platform capabilities to solve new data problems and challenges\n\u2022 Ensure all automated processes preserve data integrity by managing the alignment of data availability and integration processes\n\u2022 Support quantitative analysts and data scientists with data discovery and rapid assembly of large data sets from disparate sources\n\u2022 Identify opportunities for new data acquisition and new uses for existing data resources\n\u2022 Research and make recommendations for new data management technologies and software engineering practices. Collaborate on decisions around the use of new tools and practices\n\u2022 Perform quality assurance and testing according to risk assessment guidelines to minimize operational, reputation, and legal risk.\n\u2022 Define data retention policy, establish data governance best practice, and create automated anomaly detection services\n\u2022 Document and update business continuity and disaster recovery procedures.\n\u2022 Engage in ongoing collaboration with data architects, modelers and other members to achieve common goals.\n\u2022 Provide guidance to development teams regarding best practices and design patterns for analytics solutions. Coach and provide guidance to junior team members\n\u2022 Produce and maintain support documentation for ongoing operations.\n\u2022 Act as Tier-2/3 support to troubleshoot and resolve technical issues with production data models and\n\u2022 Turn complex data into easy to understand data models that are aligned to business objectives\n\u2022 Develop a user experience that is simple, yet flexible and enable the data scientists and business intelligence developers that use this data\n\u2022 Incorporate data governance and access controls for data management and access in Tableau\n\u2022 Manage and coach data analyst on the team in their analytics development journey\n\nWhat do you need to succeed?\n\u2022 Minimum undergraduate degree in Mathematics, Computer Science, Engineering or equivalent\n\u2022 Expertise in visual data model design and business intelligence principles\n\u2022 5+ years of experience in:\n\u2022 Business Intelligence, Data Warehousing, Data Integration, Analytics and Big Data\n\u2022 Cloud platforms like Amazon Web Services (AWS)\n\u2022 SQL Programming, PL/SQL and stored procedures\n\u2022 Experience with Glue and ETL development is a bonus\n\u2022 Experience working with Cloud technologies like Amazon Web Services (AWS)\n\u2022 Working in an agile development environment including rapid prototyping during sprints\n\nCompetencies:\n\u2022 Ability to learn an unfamiliar business processes quickly, adaptable to rapidly evolving requirements\n\u2022 Strong communication and relationship-building skills,\n\u2022 Experience with hybrid data environments that leverage both distributed and relational database technologies to support analytics services\n\u2022 Solid understanding of data warehousing principles, architecture and its implementation in complex environments.\n\u2022 Hands-on experience with development of ELT/ETL processes in traditional and distributed environments\n\u2022 Experience as designer of complex Dimensional data models for analytics services\n\u2022 Experience with development for Microsoft SQL Server Analysis Services or equivalent technologies\n\u2022 Experience with various testing methodologies and user acceptance testing.\n\u2022 Experience with AWS data engineering toolset including AWS Glue, Redshift and S3 buckets\n\u2022 Solid skills in SQL, Python and other languages used in data manipulation\n\u2022 Experience with Hadoop and Big Data technology\n\u2022 Experience with processing large datasets from multiple sources.\n\u2022 Ability to operate effectively and independently in a dynamic, fluid environment.\n\u2022 Strong verbal and written communications skills with experience in relating complex concepts to non-technical users.\n\u2022 Demonstrated ability to exchange ideas and convey complex information clearly and concisely\n\u2022 Proven ability to lead and drive projects and assignments to completion\n\u2022 Experience with creating semantic layers / data sources and organizing them in structured dimensions and measures for business use\n\u2022 Ability to work independently, manage engagements or parts of large engagements directly with business partners.\n\u2022 Solid understanding of how to consolidate and transform data to meaningful and actionable information\n\u2022 Ability to draw out meaningful business insights by synthesizing information from multiple sources\n\u2022 Strong problem solving and troubleshooting skills with the ability to exercise mature judgment.\n\nWhat will be nice to have?\n\u2022 Tableau PostgreSQL and Snowflake hands-on analysis\n\u2022 Tableau Prep and Conductor to create data prep flows\n\u2022 Experience with other ETL tools like Informatica\n\u2022 Experience in Group Benefits and Insurance or Financial Services Industry\n\nUnique Requirements?\n\u2022 The candidate selected for this role is required to attain Canadian Reliability Security Clearance (administered by submitting fingerprints to the RCMP, who then conduct min. 5 year history checks)\n\u2022 To see if you are eligible for this clearance, please review the section 201 on the Federal Government site (https://www.tpsgc-pwgsc.gc.ca/esc-src/personnel/pdcf-rsrp-eng.html)\n\nWhat\u2019s in it for you?\n\u2022 Great Place to Work\u00ae Certified in Canada and the US - 2022\n\u2022 Great Place to Work\u00ae award for Best Workplaces for #HybridWork\n\u2022 2022 Named \u201cBest Places to Work\u201d by Glassdoor - 2021\n\u2022 Canada Award for Excellence for Mental Health at Work\n\u2022 2021 Flexible hybrid work model including in-country work-from-home if you prefer.\n\nThe Base Pay range is for the primary location for which the job is posted. It may vary depending on the work location of the successful candidate or other factors. In addition to Base Pay, eligible Sun Life employees participate in various incentive plans, payment under which is discretionary and subject to individual and company performance. Certain sales focused roles have sales incentive plans based on individual or group sales results.\n\nDiversity and inclusion have always been at the core of our values at Sun Life. A diverse workforce with wide perspectives and creative ideas benefits our clients, the communities where we operate and all of us as colleagues. We welcome applications from qualified individuals from all backgrounds.\n\nPersons with disabilities who need accommodation in the application process or those needing job postings in an alternative format may e-mail a request to thebrightside@sunlife.com.\n\nAt Sun Life we strive to create a flexible work environment where our employees are empowered to do their best work. Several flexible work options are available and can be discussed throughout the selection process depending on the role requirements and individual needs.\n\nWe thank all applicants for showing an interest in this position. Only those selected for an interview will be contacted.\n\nSalary Range:\n\n76,000/76 000 - 125,000/125 000\n\nJob Category:\n\nAdvanced Analytics\n\nPosting End Date:\n\n27/03/2024", "highlights": "\nQualifications:\n Minimum undergraduate degree in Mathematics, Computer Science, Engineering or equivalent, Expertise in visual data model design and business intelligence principles, 5+ years of experience in:, Business Intelligence, Data Warehousing, Data Integration, Analytics and Big Data, SQL Programming, PL/SQL and stored procedures, Experience with Glue and ETL development is a bonus, Experience working with Cloud technologies like Amazon Web Services (AWS), Working in an agile development environment including rapid prototyping during sprints, Ability to learn an unfamiliar business processes quickly, adaptable to rapidly evolving requirements, Strong communication and relationship-building skills,, Experience with hybrid data environments that leverage both distributed and relational database technologies to support analytics services, Solid understanding of data warehousing principles, architecture and its implementation in complex environments, Hands-on experience with development of ELT/ETL processes in traditional and distributed environments, Experience as designer of complex Dimensional data models for analytics services, Experience with development for Microsoft SQL Server Analysis Services or equivalent technologies, Experience with various testing methodologies and user acceptance testing, Experience with AWS data engineering toolset including AWS Glue, Redshift and S3 buckets, Solid skills in SQL, Python and other languages used in data manipulation, Experience with Hadoop and Big Data technology, Experience with processing large datasets from multiple sources, Ability to operate effectively and independently in a dynamic, fluid environment, Strong verbal and written communications skills with experience in relating complex concepts to non-technical users, Demonstrated ability to exchange ideas and convey complex information clearly and concisely, Proven ability to lead and drive projects and assignments to completion, Experience with creating semantic layers / data sources and organizing them in structured dimensions and measures for business use, Ability to work independently, manage engagements or parts of large engagements directly with business partners, Solid understanding of how to consolidate and transform data to meaningful and actionable information, Ability to draw out meaningful business insights by synthesizing information from multiple sources, Strong problem solving and troubleshooting skills with the ability to exercise mature judgment, Tableau PostgreSQL and Snowflake hands-on analysis, Tableau Prep and Conductor to create data prep flows, Experience with other ETL tools like Informatica, Experience in Group Benefits and Insurance or Financial Services Industry, The candidate selected for this role is required to attain Canadian Reliability Security Clearance (administered by submitting fingerprints to the RCMP, who then conduct min, 5 year history checks), \nResponsibilities:\n Reporting to AVP, GB Analytics , you will accelerate the growth and application of analytics in Group Benefits, You will also leverage practical experience in applying varied data engineering techniques and design, develop and implement analytics use cases, Work with UW management and Best Practices teams to reverse engineer their existing tools, identify data needs and develop automated financial reporting capability, Review and translate existing macro-based (VBS) data scripts to SQL code to migrate UW tools to new cloud-based data models, Work directly with business stakeholders throughout the entire engagement life cycle including technical analysis, design, development, implementation and consulting efforts, Provide plans and estimates for data engineering and business intelligence initiatives, Lead development of new batch/low-latency analytical solutions that leverages both traditional and emerging technologies, Design, develop and implement highly scalable data capture and transformation processes, Act as principal designer and reviewer for new data models, make data architectural decision, and provide coaching on data modeling and process design, Create effective ETLs/ELTs to move large volumes of data from various operational systems to dimensional data models for analytics consumption, Expand and grow data existing platform capabilities to solve new data problems and challenges, Ensure all automated processes preserve data integrity by managing the alignment of data availability and integration processes, Support quantitative analysts and data scientists with data discovery and rapid assembly of large data sets from disparate sources, Identify opportunities for new data acquisition and new uses for existing data resources, Research and make recommendations for new data management technologies and software engineering practices, Collaborate on decisions around the use of new tools and practices, Perform quality assurance and testing according to risk assessment guidelines to minimize operational, reputation, and legal risk, Define data retention policy, establish data governance best practice, and create automated anomaly detection services, Document and update business continuity and disaster recovery procedures, Engage in ongoing collaboration with data architects, modelers and other members to achieve common goals, Provide guidance to development teams regarding best practices and design patterns for analytics solutions, Coach and provide guidance to junior team members, Produce and maintain support documentation for ongoing operations, Act as Tier-2/3 support to troubleshoot and resolve technical issues with production data models and, Turn complex data into easy to understand data models that are aligned to business objectives, Develop a user experience that is simple, yet flexible and enable the data scientists and business intelligence developers that use this data, Incorporate data governance and access controls for data management and access in Tableau, Manage and coach data analyst on the team in their analytics development journey, \nBenefits:\n Great Place to Work\u00ae Certified in Canada and the US - 2022, 2022 Named \u201cBest Places to Work\u201d by Glassdoor - 2021, Canada Award for Excellence for Mental Health at Work, 2021 Flexible hybrid work model including in-country work-from-home if you prefer, The Base Pay range is for the primary location for which the job is posted, In addition to Base Pay, eligible Sun Life employees participate in various incentive plans, payment under which is discretionary and subject to individual and company performance", "resume_similarity": null}