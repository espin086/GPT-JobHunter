{"job_id": "V5sHBdKsS6zSkYNwAAAAAA==", "employer_name": "Mission Cloud", "employer_logo": null, "employer_website": null, "employer_company_type": null, "job_publisher": "Lever", "job_employment_type": "FULLTIME", "job_title": "Machine Learning Engineer", "job_apply_link": "https://jobs.lever.co/missioncloud/1868e799-59d1-49cb-99e3-35819beb9e5f", "job_apply_is_direct": false, "job_apply_quality_score": 0.7529, "apply_options": [{"publisher": "Lever", "apply_link": "https://jobs.lever.co/missioncloud/1868e799-59d1-49cb-99e3-35819beb9e5f", "is_direct": false}], "job_description": "As a Machine Learning Engineer, you will report to the Consulting Manager, Data, Analytics & Machine Learning and work with our Big Data Consultants and Architects to design, develop, and build MLOps workflows and help deploy machine learning models to solve complex business problems. You will help our customers build modern data solutions on the AWS stack.\n\nThis position is 100% remote with up to 25% travel required.\n\nResponsibilities\n\u2022 Under the supervision of Big Data Consultants and Architects, work with multiple clients simultaneously to implement enterprise-wide scalable operations on AWS\n\u2022 Deploy and monitor machine learning models on AWS using tools such as SageMaker\n\u2022 Implement machine learning pipelines including data cleaning, training, evaluation and deployment\n\u2022 Develop models from customer data to meet customer goals\n\u2022 Write infrastructure as code scripts in CDK or Terraform to help make service deployment more efficient and consistent\n\u2022 Create data visualizations and reports from the data that has been extracted, transformed and loaded with tool such as Amazon Quicksight\n\u2022 Collaborate with data scientists, data engineers, and product managers to document requirement and delivery machine learning solutions\n\u2022 Develop and maintain data pipelines, feature engineering, and model training and deployment framework\n\u2022 Conduct exploratory data analysis, data preprocessing, and data cleaning\n\u2022 Perform model evaluation, selection, and optimization\n\u2022 Implement and maintain automated testing and monitoring for machine learning models in production\n\nRequirements\n\u2022 Design & implementation experience with distributed applications\n\u2022 Experience in database architectures and data/MLOps pipeline development\n\u2022 Ability to work with loading and extracting data from Glue, SQL, DDL, DML commands\n\u2022 Working knowledge of AWS data technologies, like Sagemake\n\u2022 MLFlow or Sagemaker MLOps experience\n\u2022 Working knowledge of machine learning libraries and frameworks such as TensorFlow, PyTorch, scikit-learn, or similar\n\u2022 Python or R experience\n\u2022 Working knowledge of AWS cloud computing platforms and services such as Sagemaker, S3, Athena,and Lambda\n\u2022 Working knowledge of software engineering principles and best practices, including version control, testing, and continuous integration/continuous deployment (CI/CD)\n\u2022 Ability to handle unstructured, semi-structured data, working in a data lake environment\n\u2022 Ability to work in an Agile environment\n\u2022 Working knowledge of software development tools and methodologies\n\u2022 Presentation skills with a high degree of comfort speaking with IT management, customers, and developers\n\u2022 AWS Certification (required within 6 months of hire)\n\nPerks & Benefits\n\u2022 We offer a reward and wellbeing package to enable your work to fit with your life. These can include, but not limited to:\n\u2022 Access to health, vision and dental insurance with options 100% covered by Mission Cloud for employee and their dependents\n\u2022 Flexible Spending Accounts (Healthcare & Dependent Care)\n\u2022 Generous Paid Time Off (FlexPTO, parental leave, volunteering time off)\n\u2022 Reproductive health benefits\n\u2022 Pet insurance\n\u2022 401k matching program\n\u2022 Life insurance paid by Mission Cloud\n\u2022 Monthly flex stipend\n\u2022 Monthly cell phone stipend\n\u2022 Home office expense benefit\n\u2022 An internal department dedicated to helping team members on their career path\n\u2022 Inclusive work environment with several Employee Resource Groups\n\n$140,475 - $177,644 a year\nPlacement within the range is determined by a variety of factors, including but not limited to knowledge, skills, and ability as evaluated during the interview process.\nLevel P3: $140,475 - $177,644\n\nCommitment to Diversity and Inclusion\n\nWe are committed to diversity and inclusion. We value every individual\u2019s unique story, experience, and perspective. We aim to amplify the voices of our team members and our community to create a safe, empathetic, and inclusive environment where everyone can contribute to one\u2019s authentic self. Mission Cloud makes every effort to ensure that all employees are compensated fairly regardless of gender, ethnicity, race, or past salary history. We understand that fair compensation practices establish that diversity, fair hiring processes, and fair pay are part of who we are as a company and maintain positive employee morale. We use market data to define salary ranges for each role and regularly review compensation adjustments as needed based on salary range updates.\n\nMission Cloud is an Equal Opportunity Employer and participant in the U.S. Federal E-Verify program. Mission Cloud will consider qualified applicants with criminal histories in a manner consistent with The Los Angeles Fair Chance Initiative for Hiring Ordinance.\n\nAbout Mission Cloud\n\nMission Cloud is an Amazon Web Services (AWS) Premier Consulting Partner and MSP. Clients depend on us to expertly and securely architect, migrate, manage, and optimize their cloud environments.\n\nMission Cloud\u2019s team of AWS Certified Solutions Architects and DevOps Engineers are ready to help you harness the full power of the AWS cloud to transform your business and operations.", "job_is_remote": false, "job_posted_at_timestamp": 1689811200, "job_posted_at_datetime_utc": "2023-07-20T00:00:00.000Z", "job_city": "Beverly Hills", "job_state": "CA", "job_country": "US", "job_latitude": 34.066845, "job_longitude": -118.39562, "job_benefits": ["retirement_savings", "dental_coverage", "health_insurance", "paid_time_off"], "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=machine+learning+engineer&start=20&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=machine+learning+engineer&htidocid=V5sHBdKsS6zSkYNwAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": null, "job_offer_expiration_timestamp": null, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": null, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": false, "degree_preferred": false, "professional_certification_mentioned": true}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {"Qualifications": ["Design & implementation experience with distributed applications", "Experience in database architectures and data/MLOps pipeline development", "Ability to work with loading and extracting data from Glue, SQL, DDL, DML commands", "Working knowledge of AWS data technologies, like Sagemake", "MLFlow or Sagemaker MLOps experience", "Working knowledge of machine learning libraries and frameworks such as TensorFlow, PyTorch, scikit-learn, or similar", "Python or R experience", "Working knowledge of AWS cloud computing platforms and services such as Sagemaker, S3, Athena,and Lambda", "Working knowledge of software engineering principles and best practices, including version control, testing, and continuous integration/continuous deployment (CI/CD)", "Ability to handle unstructured, semi-structured data, working in a data lake environment", "Ability to work in an Agile environment", "Working knowledge of software development tools and methodologies", "Presentation skills with a high degree of comfort speaking with IT management, customers, and developers", "AWS Certification (required within 6 months of hire)"], "Responsibilities": ["As a Machine Learning Engineer, you will report to the Consulting Manager, Data, Analytics & Machine Learning and work with our Big Data Consultants and Architects to design, develop, and build MLOps workflows and help deploy machine learning models to solve complex business problems", "You will help our customers build modern data solutions on the AWS stack", "This position is 100% remote with up to 25% travel required", "Under the supervision of Big Data Consultants and Architects, work with multiple clients simultaneously to implement enterprise-wide scalable operations on AWS", "Deploy and monitor machine learning models on AWS using tools such as SageMaker", "Implement machine learning pipelines including data cleaning, training, evaluation and deployment", "Develop models from customer data to meet customer goals", "Write infrastructure as code scripts in CDK or Terraform to help make service deployment more efficient and consistent", "Create data visualizations and reports from the data that has been extracted, transformed and loaded with tool such as Amazon Quicksight", "Collaborate with data scientists, data engineers, and product managers to document requirement and delivery machine learning solutions", "Develop and maintain data pipelines, feature engineering, and model training and deployment framework", "Conduct exploratory data analysis, data preprocessing, and data cleaning", "Perform model evaluation, selection, and optimization", "Implement and maintain automated testing and monitoring for machine learning models in production"], "Benefits": ["We offer a reward and wellbeing package to enable your work to fit with your life", "Access to health, vision and dental insurance with options 100% covered by Mission Cloud for employee and their dependents", "Flexible Spending Accounts (Healthcare & Dependent Care)", "Generous Paid Time Off (FlexPTO, parental leave, volunteering time off)", "Reproductive health benefits", "Pet insurance", "401k matching program", "Life insurance paid by Mission Cloud", "Monthly flex stipend", "Monthly cell phone stipend", "Home office expense benefit", "An internal department dedicated to helping team members on their career path", "$140,475 - $177,644 a year"]}, "job_job_title": "Learning engineer", "job_posting_language": "en", "job_onet_soc": "15111100", "job_onet_job_zone": "5"}