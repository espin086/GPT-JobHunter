{"job_id": "xjnMfBVr2x8KQ6NaAAAAAA==", "employer_name": "Jobot", "employer_logo": null, "employer_website": null, "employer_company_type": null, "job_publisher": "Monster", "job_employment_type": "FULLTIME", "job_title": "Remote Data Engineer", "job_apply_link": "https://www.monster.com/job-openings/remote-data-engineer-phoenix-az--891abfdf-f148-4480-b6f5-be269c9fcbee?mstr_dist=true", "job_apply_is_direct": true, "job_apply_quality_score": 0.5696, "apply_options": [{"publisher": "Monster", "apply_link": "https://www.monster.com/job-openings/remote-data-engineer-phoenix-az--891abfdf-f148-4480-b6f5-be269c9fcbee?mstr_dist=true", "is_direct": true}], "job_description": "This Jobot Job is hosted by: Conner Ferguson\nAre you a fit? Easy Apply now by clicking the \"Quick Apply\" button and sending us your resume.\nSalary: $110,000 - $135,000 per year\n\nA bit about us:\n\nAs a Data Engineer, you will be responsible for building and maintaining our data pipeline infrastructure, optimizing data workflows and implementing efficient data storage solutions. You will be responsible for optimizing reports and delivering data up stream and work closely with the IT team to enforce data quality standards over vast amounts of data. You will report to the CTO but will work closely with stakeholders to improve data streams across the organization for analytics and data science purposes.\n\nConducts complex, important work under minimal supervision and with wide latitude for independent judgment. Typically requires a bachelor's degree (or international equivalent) and 6+ years of relevant experience.\n\nWhy join us?\n\nRemote\nHealth\nDental\nVision\n401k\n\nJob Details\n\nAs a Data Engineer, you will:\n\n\u00b7 Build and maintain scalable and efficient data processing pipelines, using various technologies such SSIS.\n\u00b7 Develop and maintain monitoring tools to ensure the health and reliability of our data infrastructure.\n\u00b7 Optimize poor performing queries.\n\u00b7 Determine, enforce and document database policies, procedures and standards.\n\u00b7 Perform tests and evaluations regularly to ensure data security, privacy and integrity.\n\u00b7 Monitor database performance, implement changes and apply new patches and versions when required.\n\u00b7 Ensure that all data-related processes comply with relevant data privacy and security regulations.\nCollaborate with stakeholders to understand reporting requirements and performance expectations.\n\nRequirements:\n\n\u00b7 6+ years of industry specific experience\n\u00b7 Ability to read, write, and speak the English language proficiently.\n\u00b7 Proven working experience with Microsoft SQL Server, MongoDB, and Postgres SQL\n\u00b7 Proven experience with SSIS and SSRS\n\u00b7 Proven Experience with Tableau reporting/ building\n\u00b7 Hands-on experience with database standards and end user applications\n\u00b7 Familiarity with database design, documentation and SQL coding\n\u00b7 Experience with cloud-based data storage solutions such as AWS S3, and Azure Blob Storage.\n\u00b7 Strong understanding of data modeling, data warehousing, and ETL processes.\n\nInterested in hearing more? Easy Apply now by clicking the \"Quick Apply\" button.\n\nBenefits:\n401K, Employee Events, Employee Referral Program, Flexible Schedules, Free Food and Coffee, Game Rooms, Life Insurance, Maternity/Paternity Paid Leave, Medical, Dental and Vision, On Site Cafeteria, Paid Holidays, Paid sick days, Parking , Performance bonus, Professional Development, Retirement / Pension Plans, Vacation/paid time off, Work From Home\n\nAbout the Company:\nJobot\n\nCompany Size:\n500 to 999 employees\n\nIndustry:\nComputer Hardware\n\nFounded:\n2018\n\nWebsite:\nhttps://jobot.com/", "job_is_remote": false, "job_posted_at_timestamp": 1709769600, "job_posted_at_datetime_utc": "2024-03-07T00:00:00.000Z", "job_city": "Phoenix", "job_state": "AZ", "job_country": "US", "job_latitude": 33.448376, "job_longitude": -112.074036, "job_benefits": ["health_insurance", "paid_time_off", "dental_coverage", "retirement_savings"], "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer&start=70&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer&htidocid=xjnMfBVr2x8KQ6NaAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2024-04-06T04:22:11.000Z", "job_offer_expiration_timestamp": 1712377331, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 72, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": true, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": 110000, "job_max_salary": 135000, "job_salary_currency": "USD", "job_salary_period": "YEAR", "job_highlights": {"Qualifications": ["Typically requires a bachelor's degree (or international equivalent) and 6+ years of relevant experience", "6+ years of industry specific experience", "Ability to read, write, and speak the English language proficiently", "Proven working experience with Microsoft SQL Server, MongoDB, and Postgres SQL", "Proven experience with SSIS and SSRS", "Proven Experience with Tableau reporting/ building", "Hands-on experience with database standards and end user applications", "Familiarity with database design, documentation and SQL coding", "Experience with cloud-based data storage solutions such as AWS S3, and Azure Blob Storage", "Strong understanding of data modeling, data warehousing, and ETL processes"], "Responsibilities": ["As a Data Engineer, you will be responsible for building and maintaining our data pipeline infrastructure, optimizing data workflows and implementing efficient data storage solutions", "You will be responsible for optimizing reports and delivering data up stream and work closely with the IT team to enforce data quality standards over vast amounts of data", "You will report to the CTO but will work closely with stakeholders to improve data streams across the organization for analytics and data science purposes", "Conducts complex, important work under minimal supervision and with wide latitude for independent judgment", "Build and maintain scalable and efficient data processing pipelines, using various technologies such SSIS", "Develop and maintain monitoring tools to ensure the health and reliability of our data infrastructure", "Optimize poor performing queries", "Determine, enforce and document database policies, procedures and standards", "Perform tests and evaluations regularly to ensure data security, privacy and integrity", "Monitor database performance, implement changes and apply new patches and versions when required", "Ensure that all data-related processes comply with relevant data privacy and security regulations", "Collaborate with stakeholders to understand reporting requirements and performance expectations"], "Benefits": ["Salary: $110,000 - $135,000 per year", "401K, Employee Events, Employee Referral Program, Flexible Schedules, Free Food and Coffee, Game Rooms, Life Insurance, Maternity/Paternity Paid Leave, Medical, Dental and Vision, On Site Cafeteria, Paid Holidays, Paid sick days, Parking , Performance bonus, Professional Development, Retirement / Pension Plans, Vacation/paid time off, Work From Home"]}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4"}