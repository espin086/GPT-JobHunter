{"job_id": "UC-N5DXRJtUOLRJNAAAAAA==", "employer_name": "CGI Group, Inc.", "employer_logo": "https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/CGI_logo.svg/1280px-CGI_logo.svg.png", "employer_website": "http://www.cgi.com", "employer_company_type": "Computer Services", "job_publisher": "Glassdoor", "job_employment_type": "FULLTIME", "job_title": "Senior Data Engineer", "job_apply_link": "https://www.glassdoor.com/job-listing/senior-data-engineer-cgi-group-inc-JV_IC1130359_KO0,20_KE21,34.htm?jl=1009144857460", "job_apply_is_direct": false, "job_apply_quality_score": 0.5646, "apply_options": [{"publisher": "Glassdoor", "apply_link": "https://www.glassdoor.com/job-listing/senior-data-engineer-cgi-group-inc-JV_IC1130359_KO0,20_KE21,34.htm?jl=1009144857460", "is_direct": false}], "job_description": "Senior Data Engineer\n\nPosition Description\n\nBecome part of a team to help a large government agency support transformative biomedical and health breakthroughs. CGI Federal is seeking a Data Engineer to support advanced research projects that will provide healthcare solutions for all.\n\u2022 **This is a hybrid role requiring 2 days onsite/week in Fairfax, VA or Baltimore, MD***\n\nYour future duties and responsibilities\n\u2022 Develop and maintain data pipelines for integrating biomedical datasets securely, adhering to privacy-preserving methodologies\n\u2022 Interprets data, analyzes results using statistical techniques, and provides ongoing reports.\n\u2022 Collaborate with the ML Ops Engineer on smooth flow of data for training and deployment of privacy-focused ML models.\n\u2022 Executes quantitative analyses that translate data into actionable insights.\n\u2022 Optimize data storage and retrieval processes for efficiency.\n\u2022 Provides analytical and data-driven decision-making support for key projects.\n\u2022 Designs, manages, and conducts quality control procedures for data sets using data from multiple systems.\n\u2022 Creates data collection frameworks for structured and unstructured data.\n\u2022 Applies data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources.\n\u2022 Applies and implements best practices for data auditing, scalability, reliability and application performance.\n\u2022 Develops data models by studying existing data warehouse architecture; evaluating alternative logical data models including planning and execution tables; applying metadata and modeling standards, guidelines, conventions, and procedures; planning data classes and sub-classes, indexes, directories, repositories, messages, sharing, replication, back-up, retention, and recovery.\n\nRequired qualifications to be successful in this role\n\u2022 Bachelor's degree in computer science, Engineering, Physics, Mathematics or a related technical or scientific field with a minimum of 8 years of experience in data management.\n\u2022 Proficiency in languages such as Python, SQL, and R is essential. These languages are used for data manipulation, analysis, and scripting.\n\u2022 Knowledge of how to build and maintain database systems.\n\u2022 Able to use services on Azure like Azure Data Factor\n\u2022 Understanding both relational databases (e.g., MySQL, PostgreSQL) and NoSQL databases (e.g., MongoDB, Cassandra) is valuable.\n\u2022 Familiarity with ETL tools and processes is crucial for data integration and transformation.\n\no Examples include Apache NiFi, Talend, and Informatica.\n\no Familiarity with tools like Tableau, Power BI, or Matplotlib.\n\no Apache Hadoop and Apache Spark: Distributed computing frameworks for big data processing.\n\u2022 Knowledge of big data technologies like Hadoop, Spark, and Kafka is essential for handling large-scale data processing.\n\u2022 Understanding data warehousing concepts and tools (e.g., Amazon Redshift, Google BigQuery) is important.\n\u2022 Possesses a foundational understanding of machine learning principles, algorithms, and statistical concepts is beneficial.\n\u2022 Use Python for data manipulation, scripting, and building data pipelines.\n\u2022 Ability to query and manage relational databases using SQL\n\u2022 Requires strong organizational and communication skills, written and verbal, with the ability to work well with cross-functional teams and troubleshoot issues and optimize data workflows.\n\nNice to Have:\n\u2022 Emerging Technologies (e.g. Blockchain, Zero trust)\n\nCGI is required by law in some jurisdictions to include a reasonable estimate of the compensation range for this role. The determination of this range includes various factors not limited to: skill set level; experience and training; and licensure and certifications. CGI typically does not hire individuals at or near the top of the range for their role. Compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $91,500 - $160,200.\n\n#CGIFederalJob\n\n#HSS\n\n#DICE\n\n#LI-RJ1\n\nInsights you can act on\n\nWhile technology is at the heart of our clients' digital transformation, we understand that people are at the heart of business success.\n\nWhen you join CGI, you become a trusted advisor, collaborating with colleagues and clients to bring forward actionable insights that deliver meaningful and sustainable outcomes. We call our employees \"members\" because they are CGI shareholders and owners and owners who enjoy working and growing together to build a company we are proud of. This has been our Dream since 1976, and it has brought us to where we are today - one of the world's largest independent providers of IT and business consulting services.\n\nAt CGI, we recognize the richness that diversity brings. We strive to create a work culture where all belong and collaborate with clients in building more inclusive communities. As an equal-opportunity employer, we want to empower all our members to succeed and grow. If you require an accommodation at any point during the recruitment process, please let us know. We will be happy to assist.\n\nReady to become part of our success story? Join CGI - where your ideas and actions make a difference.\n\nQualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, pregnancy, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, height, weight, or any other legally protected status or characteristics.\n\nCGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com . You will need to reference the Position ID of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a Position ID will not be returned.\n\nWe make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.\n\nAll CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. CGI will consider for employment qualified applicants with arrests and conviction records in accordance with all local regulations and ordinances.\n\nCGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI's legal duty to furnish information.", "job_is_remote": false, "job_posted_at_timestamp": 1708905600, "job_posted_at_datetime_utc": "2024-02-26T00:00:00.000Z", "job_city": null, "job_state": null, "job_country": "US", "job_latitude": 37.09024, "job_longitude": -95.71289, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineering&start=70&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineering&htidocid=UC-N5DXRJtUOLRJNAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": "2024-07-15T00:00:00.000Z", "job_offer_expiration_timestamp": 1721001600, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 96, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": true, "degree_preferred": true, "professional_certification_mentioned": true}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {"Qualifications": ["Bachelor's degree in computer science, Engineering, Physics, Mathematics or a related technical or scientific field with a minimum of 8 years of experience in data management", "Proficiency in languages such as Python, SQL, and R is essential", "These languages are used for data manipulation, analysis, and scripting", "Knowledge of how to build and maintain database systems", "Able to use services on Azure like Azure Data Factor", "Understanding both relational databases (e.g., MySQL, PostgreSQL) and NoSQL databases (e.g., MongoDB, Cassandra) is valuable", "Familiarity with ETL tools and processes is crucial for data integration and transformation", "Examples include Apache NiFi, Talend, and Informatica", "Familiarity with tools like Tableau, Power BI, or Matplotlib", "Apache Hadoop and Apache Spark: Distributed computing frameworks for big data processing", "Knowledge of big data technologies like Hadoop, Spark, and Kafka is essential for handling large-scale data processing", "Understanding data warehousing concepts and tools (e.g., Amazon Redshift, Google BigQuery) is important", "Use Python for data manipulation, scripting, and building data pipelines", "Ability to query and manage relational databases using SQL", "Requires strong organizational and communication skills, written and verbal, with the ability to work well with cross-functional teams and troubleshoot issues and optimize data workflows", "Emerging Technologies (e.g. Blockchain, Zero trust)"], "Responsibilities": ["Develop and maintain data pipelines for integrating biomedical datasets securely, adhering to privacy-preserving methodologies", "Interprets data, analyzes results using statistical techniques, and provides ongoing reports", "Collaborate with the ML Ops Engineer on smooth flow of data for training and deployment of privacy-focused ML models", "Executes quantitative analyses that translate data into actionable insights", "Optimize data storage and retrieval processes for efficiency", "Provides analytical and data-driven decision-making support for key projects", "Designs, manages, and conducts quality control procedures for data sets using data from multiple systems", "Creates data collection frameworks for structured and unstructured data", "Applies data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources", "Applies and implements best practices for data auditing, scalability, reliability and application performance", "Develops data models by studying existing data warehouse architecture; evaluating alternative logical data models including planning and execution tables; applying metadata and modeling standards, guidelines, conventions, and procedures; planning data classes and sub-classes, indexes, directories, repositories, messages, sharing, replication, back-up, retention, and recovery"], "Benefits": ["A reasonable estimate of the current range is $91,500 - $160,200"]}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4", "job_naics_code": "541512", "job_naics_name": "Computer Systems Design Services"}