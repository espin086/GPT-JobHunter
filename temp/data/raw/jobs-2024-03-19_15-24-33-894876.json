{"job_id": "jQidj_ZFYnwcKziOAAAAAA==", "employer_name": "2100 NVIDIA USA", "employer_logo": null, "employer_website": null, "employer_company_type": null, "job_publisher": "Workday", "job_employment_type": "FULLTIME", "job_title": "Principal Machine Learning Engineer, Content Safety and ML Fairness", "job_apply_link": "https://nvidia.wd5.myworkdayjobs.com/en-US/NVIDIAExternalCareerSite/job/Principal-Machine-Learning-Engineer--Content-Safety-and-ML-Fairness_JR1978571", "job_apply_is_direct": false, "job_apply_quality_score": 0.8388, "apply_options": [{"publisher": "Workday", "apply_link": "https://nvidia.wd5.myworkdayjobs.com/en-US/NVIDIAExternalCareerSite/job/Principal-Machine-Learning-Engineer--Content-Safety-and-ML-Fairness_JR1978571", "is_direct": false}, {"publisher": "Media Bistro", "apply_link": "https://www.mediabistro.com/jobs/158995939-principal-machine-learning-engineer-content-safety-and-ml-fairness", "is_direct": false}], "job_description": "NVIDIA is seeking a Principle Machine Learning Engineer to lead our Content Safety & ML Fairness efforts for LLMs across all of our Research and Production Engineering teams, and to coordinate with Legal, Policy, Ethics and Security. Content Safety & ML Fairness are essential to the responsible development and deploying Large Language Models (LLMs). NVIDIA is in a unique position: we are developing AI-based products across multiple domains, and we collaborate with many exciting AI companies as partners and customers. In this role, you\u2019ll work with the teams who are developing Large Language Models (LLMs) aka Generative AI for text. Our LLMs are a growing area of AI products including models and services, and we are committed to ensuring that they are used safely and responsibly. This key position will ensure the highest content safety possible by reducing exposure to inappropriate material, preventing bias and discrimination which is essential to protect both individual rights and to achieve the best quality of results including accuracy and completeness of information. By prioritizing safety and fairness, we can ensure that LLMs benefit everyone and contribute to a better future for all. What you'll be doing: Craft, orchestrate and realize the Content Safety & ML Fairness vision, mission, strategy, work and delivery across multi-functional teams. Conduct technical review of existing methods and emerging approaches from academia and industry, and be our expert on what we can purchase or open source vs building. Including staying up-to-date with the latest research and advancements in Content Safety and ML Fairness. Research and implement innovative techniques for bias detection and mitigation in LLMs and systems using LLMs like RAGs. Follow, connect and guide the work across Foundation, Alignment and PEFT modeling and evaluation work, as well as pre-and-post Inference-time guardrails, dataset assessment, and model evaluation tools. Define one technical roadmap for these teams. Ensure the problems are solved in the most appropriate place in a sophisticated landscape of models derived from other models. Define the datasets and modeling techniques, classification and evaluation strategy for designing, training and evaluating models and end-to-end systems for Content Safety and ML Fairness. Including a mix of LLM, Supervised learning, and other approaches. Ensure high quality execution, review, and (where applicable) threshold of models. Define and supervise key metrics for responsible LLM behavior and usage. Follow the best MLOps practices of automation, monitoring, scale, safety, fairness. Develop a unified MLOps methodology that ML teams can follow to be highly productive and deliver safe and fair AI products. Contribute to the MLOps platform and develop safety and fairness tools to help ML teams be more effective. Champion standard methodologies for responsible LLM development and deployment across the company and our partners. Collaborate with other engineers, data scientists, and researchers to develop and implement solutions to content safety and ML fairness challenges. What we need to see: You have a Master\u2019s or PhD in Computer Architecture, Computer Science, Electrical Engineering or related field or equivalent experience. Strong understanding of machine learning principles and algorithms. 8+ years of Work Experience in developing and deploying machine learning models in production. Collaborated with multiple teams to bring research into enterprise, developer or consumer products. Ability to lead technical projects from problem to solution. Experience with two or more of the following broader areas for 5+ years: ML Fairness, Content Safety, Deliberative Misinformation, Robustness, Security, or related areas. Experience with one or more of the following areas within Content Safety: Hate/Harassment, Sexualized, Harmful/Violent, or other specific areas from your application. Background with ML Fairness/De-biasing: de-biasing of models at training, de-biasing of results at inference, fairness metrics and bias detection techniques. Experience with explainable AI (XAI) techniques, and large datasets. Ways to stand out from the crowd: Have more than the minimum experience required within the Content Safety and ML Fairness areas listed above Experience with Robustness including Hallucinations, Digressions, Generative Misinformation. Background with GenAI Security including Prompt Stability, Model Extraction, Confidentiality/Data Extraction, Integrity, Availability and Adversarial Robustness. Experience with legal and regulatory compliance. Experience with leadership in Content Safety and/or ML Fairness across large organizations with multiple teams/groups, with a consistent record of extensive indirect influence. With highly competitive salaries and a comprehensive benefits package, NVIDIA is widely considered to be one of the technology industry's most desirable employers. We have some of the most forward-thinking and hardworking people in the world working with us and our engineering teams are growing fast in some of the hottest pioneering fields: Deep Learning, Artificial Intelligence, and Large Language Models. If you're a creative engineer with a real passion for robust and enjoyable user experiences, we want to hear from you! The base salary range is 272,000 USD - 419,750 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions. You will also be eligible for equity and benefits. NVIDIA accepts applications on an ongoing basis. NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law. NVIDIA is a Learning Machine NVIDIA pioneered accelerated computing to tackle challenges no one else can solve. Our work in AI and the metaverse is transforming the world's largest industries and profoundly impacting society. Learn more about NVIDIA.", "job_is_remote": true, "job_posted_at_timestamp": 1709769600, "job_posted_at_datetime_utc": "2024-03-07T00:00:00.000Z", "job_city": "Santa Clara", "job_state": "CA", "job_country": "US", "job_latitude": 37.354107, "job_longitude": -121.95524, "job_benefits": ["health_insurance"], "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=machine+learning&start=20&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=machine+learning&htidocid=jQidj_ZFYnwcKziOAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": null, "job_offer_expiration_timestamp": null, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": 96, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": true, "degree_preferred": false, "professional_certification_mentioned": false}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {"Qualifications": ["What we need to see: You have a Master\u2019s or PhD in Computer Architecture, Computer Science, Electrical Engineering or related field or equivalent experience", "Strong understanding of machine learning principles and algorithms", "8+ years of Work Experience in developing and deploying machine learning models in production", "Collaborated with multiple teams to bring research into enterprise, developer or consumer products", "Experience with two or more of the following broader areas for 5+ years: ML Fairness, Content Safety, Deliberative Misinformation, Robustness, Security, or related areas", "Experience with explainable AI (XAI) techniques, and large datasets", "Ways to stand out from the crowd: Have more than the minimum experience required within the Content Safety and ML Fairness areas listed above Experience with Robustness including Hallucinations, Digressions, Generative Misinformation", "Background with GenAI Security including Prompt Stability, Model Extraction, Confidentiality/Data Extraction, Integrity, Availability and Adversarial Robustness", "Experience with legal and regulatory compliance", "Experience with leadership in Content Safety and/or ML Fairness across large organizations with multiple teams/groups, with a consistent record of extensive indirect influence"], "Responsibilities": ["What you'll be doing: Craft, orchestrate and realize the Content Safety & ML Fairness vision, mission, strategy, work and delivery across multi-functional teams", "Conduct technical review of existing methods and emerging approaches from academia and industry, and be our expert on what we can purchase or open source vs building", "Including staying up-to-date with the latest research and advancements in Content Safety and ML Fairness", "Research and implement innovative techniques for bias detection and mitigation in LLMs and systems using LLMs like RAGs", "Follow, connect and guide the work across Foundation, Alignment and PEFT modeling and evaluation work, as well as pre-and-post Inference-time guardrails, dataset assessment, and model evaluation tools", "Define one technical roadmap for these teams", "Ensure the problems are solved in the most appropriate place in a sophisticated landscape of models derived from other models", "Define the datasets and modeling techniques, classification and evaluation strategy for designing, training and evaluating models and end-to-end systems for Content Safety and ML Fairness", "Including a mix of LLM, Supervised learning, and other approaches", "Ensure high quality execution, review, and (where applicable) threshold of models", "Define and supervise key metrics for responsible LLM behavior and usage", "Follow the best MLOps practices of automation, monitoring, scale, safety, fairness", "Develop a unified MLOps methodology that ML teams can follow to be highly productive and deliver safe and fair AI products", "Contribute to the MLOps platform and develop safety and fairness tools to help ML teams be more effective", "Champion standard methodologies for responsible LLM development and deployment across the company and our partners", "Collaborate with other engineers, data scientists, and researchers to develop and implement solutions to content safety and ML fairness challenges"], "Benefits": ["Your base salary will be determined based on your location, experience, and the pay of employees in similar positions", "You will also be eligible for equity and benefits"]}, "job_job_title": "Learning engineer", "job_posting_language": "en", "job_onet_soc": "15111100", "job_onet_job_zone": "5"}