{"job_id": "e_ah7NCHqaMBjRkcAAAAAA==", "employer_name": "YPrime", "employer_logo": "https://media.licdn.com/dms/image/C4D16AQHGeXLxXakSew/profile-displaybackgroundimage-shrink_200_800/0/1652391295142?e=2147483647&v=beta&t=8PRg-Gm3ZSaHzrZMQaB5rSqmnhAHOeLHOikZGewTXs4", "employer_website": "http://www.yprime.com", "employer_company_type": null, "job_publisher": "The Org", "job_employment_type": "FULLTIME", "job_title": "Senior Data Engineer - Contract", "job_apply_link": "https://theorg.com/org/yprime/jobs/senior-data-engineer-cont-d89b80f", "job_apply_is_direct": false, "job_apply_quality_score": 0.5522, "apply_options": [{"publisher": "The Org", "apply_link": "https://theorg.com/org/yprime/jobs/senior-data-engineer-cont-d89b80f", "is_direct": false}], "job_description": "At YPrime, we help our clients in the pharma and biotech industries to collect data from patients using mobile devices, assign patients to study treatment groups, and dispense clinical trial drugs and supplies using web apps.\u202f We\u2019re supporting life-altering research, one project at a time.\n\nIs your career in its prime?\u202f It could be!\n\nYPrime\u2019s Innovation & IT team is searching for a Senior Data Engineer. This is a contracting role, with a possibility of full-time conversion in the future.\n\nDoes our mission sound like something you can get behind?\u202f If so, here\u2019s what we need from you:\n\u2022 Advanced Python proficiency \u2013 Possess and in-depth knowledge of Python, including libraries such as Pandas and NumPy\n\u2022 Expertise in SQL \u2013 Advanced skills in SQL for complex data querying and manipulation\n\u2022 Proficiency in DBT \u2013 Strong experience in using DBT for data transformation and building\n\u2022 Familiarity with data testing frameworks to ensure data quality and accuracy\n\u2022 Experience in developing cloud data pipelines using Python\n\u2022 Significant experience with large-scale data orchestration using tools like Dagster or similar\n\nHere are some more details about the job:\n\u2022 You\u2019ll lead the engineering of robust data pipelines, primarily using DBT and Python, within an Azure environment, ensuring efficient data flow and processing.\n\u2022 You\u2019ll take full ownership of the company's DBT models, overseeing their development, maintenance, and optimization.\n\u2022 You\u2019ll be responsible for comprehensive data-testing, utilizing both Python frameworks and DBT frameworks to ensure data integrity and reliability.\n\u2022 You\u2019ll lead the migration of legacy reporting systems from SQL Server to Snowflake using DBT, ensuring a smooth transition and minimal disruption.\n\u2022 You\u2019ll manage and develop data orchestration processes, utilizing tools such as Airflow, Dagster, or Prefect, to streamline and automate data workflows.\n\u2022 You\u2019ll work closely with Product and Project teams, contributing to major project architectures and translating strategic goals into actionable plans.\n\u2022 You\u2019ll interface with legacy systems, integrating them with modern technologies to support large-scale digital, data, and analytics initiatives.\n\u2022 You\u2019ll uphold high standards for writing secure, reliable code, and foster a collaborative environment as a key team player.\n\nHave these things too? Even better!\n\u2022 Bachelor\u2019s degree or MBA in Computer Science, Information Technology, a related field, or an equivalent amount of related experience\n\u2022 Experience leading major projects in collaboration with Product and Project teams\n\u2022 Experience with legacy systems and integrating them with modern technologies\n\u2022 Demonstrated ability to translate strategy into practical action\n\u2022 Possess one or more certifications related to Cloud Technology\n\u2022 Previous experience working in an FDA-regulated industry", "job_is_remote": false, "job_posted_at_timestamp": 1708453680, "job_posted_at_datetime_utc": "2024-02-20T18:28:00.000Z", "job_city": null, "job_state": "PA", "job_country": "US", "job_latitude": 41.203323, "job_longitude": -77.19453, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer&start=50&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer&htidocid=e_ah7NCHqaMBjRkcAAAAAA%3D%3D", "job_offer_expiration_datetime_utc": null, "job_offer_expiration_timestamp": null, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": null, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": true, "degree_preferred": false, "professional_certification_mentioned": true}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {"Qualifications": ["Advanced Python proficiency \u2013 Possess and in-depth knowledge of Python, including libraries such as Pandas and NumPy", "Expertise in SQL \u2013 Advanced skills in SQL for complex data querying and manipulation", "Proficiency in DBT \u2013 Strong experience in using DBT for data transformation and building", "Experience in developing cloud data pipelines using Python", "Significant experience with large-scale data orchestration using tools like Dagster or similar", "Bachelor\u2019s degree or MBA in Computer Science, Information Technology, a related field, or an equivalent amount of related experience", "Experience leading major projects in collaboration with Product and Project teams", "Experience with legacy systems and integrating them with modern technologies", "Demonstrated ability to translate strategy into practical action", "Possess one or more certifications related to Cloud Technology", "Previous experience working in an FDA-regulated industry"], "Responsibilities": ["You\u2019ll lead the engineering of robust data pipelines, primarily using DBT and Python, within an Azure environment, ensuring efficient data flow and processing", "You\u2019ll take full ownership of the company's DBT models, overseeing their development, maintenance, and optimization", "You\u2019ll be responsible for comprehensive data-testing, utilizing both Python frameworks and DBT frameworks to ensure data integrity and reliability", "You\u2019ll lead the migration of legacy reporting systems from SQL Server to Snowflake using DBT, ensuring a smooth transition and minimal disruption", "You\u2019ll manage and develop data orchestration processes, utilizing tools such as Airflow, Dagster, or Prefect, to streamline and automate data workflows", "You\u2019ll work closely with Product and Project teams, contributing to major project architectures and translating strategic goals into actionable plans", "You\u2019ll interface with legacy systems, integrating them with modern technologies to support large-scale digital, data, and analytics initiatives", "You\u2019ll uphold high standards for writing secure, reliable code, and foster a collaborative environment as a key team player"]}, "job_job_title": "Data engineer", "job_posting_language": "en", "job_onet_soc": "15113200", "job_onet_job_zone": "4"}