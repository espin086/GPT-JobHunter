{"job_id": "xU78IxWrcwXc6Wp9AAAAAA==", "employer_name": "Publicis Sapient", "employer_logo": "https://www.publicissapient.com/content/dam/ps-rebrand/brand/ps-logo-NEW.svg", "employer_website": "https://www.publicissapient.com", "employer_company_type": "Computer Services", "job_publisher": "Publicis Sapient Careers", "job_employment_type": "FULLTIME", "job_title": "Senior Data Engineering (Snowflake)", "job_apply_link": "https://careers.publicissapient.com/job-details/743999931158007-senior-data-engineering-snowflake--minneapolis?trid=fabf8f5c-18fc-43ce-ba06-84dac34b9203", "job_apply_is_direct": false, "job_apply_quality_score": 0.9063, "apply_options": [{"publisher": "Publicis Sapient Careers", "apply_link": "https://careers.publicissapient.com/job-details/743999931158007-senior-data-engineering-snowflake--minneapolis?trid=fabf8f5c-18fc-43ce-ba06-84dac34b9203", "is_direct": false}, {"publisher": "Minnesota Jobs - Tarta.ai", "apply_link": "https://minnesota.tarta.ai/j/oxgkzooBcRajQcTjjpar0923-senior-data-engineering-snowflake-in-minneapolis-minnesota-at-publicis-sapient", "is_direct": false}, {"publisher": "Learn4Good", "apply_link": "https://www.learn4good.com/jobs/minneapolis/minnesota/info_technology/2798646542/e/", "is_direct": false}], "job_description": "Publicis Sapient is looking for a looking to add a talented Cloud Engineer to our team. This is a hands-on role, responsible for driving the architecture, design, and implementation of Snowflake for our clients. You will also apply your cloud expertise to business development and pitch activities.\n\nYour Impact:\n\n\u2022 Play a key role in delivering data-driven interactive experiences to our clients\n\n\u2022 Work closely with our clients in understanding their needs and translating them to technology solutions\n\n\u2022 Provide expertise as a technical resource to solve complex business issues that translate into data integration and database systems designs\n\n\u2022 Problem solving to resolve issues and remove barriers throughout the lifecycle of client engagements\n\n\u2022 Ensuring all deliverables are high quality by setting development standards, adhering to the standards and participating in code reviews\n\n\u2022 Participate in integrated validation and analysis sessions of components and subsystems on production servers\n\nQualifications\n\nExperience in the implementation, execution, and maintenance of Data Integration technology solutions\n\n\u2022 Experience advancing and supporting information management practices within business processes, applications and technology that underpin the data discipline (e.g. establishing data quality processes, performing data analysis, participating in technology implementation planning, implementing data integration processes, etc)\n\n\u2022 Expertise in Snowflake data modeling, ELT using snowpipe, implementing stored procedures and standard DWH and ETL concepts\n\n\u2022 Expertise in Snowflake concepts like setting up resource monitors, RBAC controls, virtual warehouse, query performance tuning, Zero copy clone, time travel and understand how to use these features\n\n\u2022 Experience in Data Migration from RDBMS to Snowflake cloud data warehouse\n\n\u2022 Experience with enterprise cloud economics\n\nUnderstanding of enterprise data management concepts (Data Governance, Data Engineering, Data Science, Data Lake, Data Warehouse, Data Sharing, Data Applications)\n\n\u2022 Hands-on expertise with SQL and SQL analytics\n\n\u2022 Industry benchmarking experience in major industries such as: Financial Services and Retail\n\nSet Yourself Apart With:\n\n\u2022 Certifications for any of the cloud services like AWS, Snowflake, GCP or Azure\n\n\u2022 Experience working with code repositories and continuous integration\n\n\u2022 Understanding of development and project methodologies", "job_is_remote": false, "job_posted_at_timestamp": 1695062540, "job_posted_at_datetime_utc": "2023-09-18T18:42:20.000Z", "job_city": "Minneapolis", "job_state": "MN", "job_country": "US", "job_latitude": 44.977753, "job_longitude": -93.26501, "job_benefits": null, "job_google_link": "https://www.google.com/search?gl=us&hl=en&rciv=jb&q=data+engineer&start=70&ibp=htl;jobs#fpstate=tldetail&htivrt=jobs&htiq=data+engineer&htidocid=xU78IxWrcwXc6Wp9AAAAAA%3D%3D", "job_offer_expiration_datetime_utc": null, "job_offer_expiration_timestamp": null, "job_required_experience": {"no_experience_required": false, "required_experience_in_months": null, "experience_mentioned": true, "experience_preferred": false}, "job_required_skills": null, "job_required_education": {"postgraduate_degree": false, "professional_certification": false, "high_school": false, "associates_degree": false, "bachelors_degree": false, "degree_mentioned": false, "degree_preferred": false, "professional_certification_mentioned": true}, "job_experience_in_place_of_education": false, "job_min_salary": null, "job_max_salary": null, "job_salary_currency": null, "job_salary_period": null, "job_highlights": {"Qualifications": ["Experience in the implementation, execution, and maintenance of Data Integration technology solutions", "Experience in Data Migration from RDBMS to Snowflake cloud data warehouse", "Experience with enterprise cloud economics", "Understanding of enterprise data management concepts (Data Governance, Data Engineering, Data Science, Data Lake, Data Warehouse, Data Sharing, Data Applications)", "Hands-on expertise with SQL and SQL analytics", "Industry benchmarking experience in major industries such as: Financial Services and Retail", "Certifications for any of the cloud services like AWS, Snowflake, GCP or Azure", "Experience working with code repositories and continuous integration", "Understanding of development and project methodologies"], "Responsibilities": ["This is a hands-on role, responsible for driving the architecture, design, and implementation of Snowflake for our clients", "You will also apply your cloud expertise to business development and pitch activities", "Play a key role in delivering data-driven interactive experiences to our clients", "Work closely with our clients in understanding their needs and translating them to technology solutions", "Provide expertise as a technical resource to solve complex business issues that translate into data integration and database systems designs", "Problem solving to resolve issues and remove barriers throughout the lifecycle of client engagements", "Ensuring all deliverables are high quality by setting development standards, adhering to the standards and participating in code reviews", "Participate in integrated validation and analysis sessions of components and subsystems on production servers", "Expertise in Snowflake data modeling, ELT using snowpipe, implementing stored procedures and standard DWH and ETL concepts"]}, "job_job_title": "Data engineering", "job_posting_language": "en", "job_onet_soc": "15113300", "job_onet_job_zone": "4", "job_naics_code": "541512", "job_naics_name": "Computer Systems Design Services"}